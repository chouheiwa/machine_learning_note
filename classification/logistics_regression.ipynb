{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from plt_one_addpt_onclick import plt_one_addpt_onclick\n",
    "from lab_utils_common import draw_vthresh\n",
    "\n",
    "plt.style.use('./deeplearning.mplstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sigmoid or Logistic Function\n",
    "$$\n",
    "g(z) = \\frac{1}{1 + e^{-z}}\\\\\n",
    "z = \\mathbf{w} \\cdot \\mathbf{x} + b \\\\\n",
    "由上式可知: \\\\\n",
    "z \\in (-\\infty,+\\infty)，且\\lim_{z \\to +\\infty}g(z) = 1\\\\\n",
    "\\lim_{z \\to -\\infty}g(z) = 0\n",
    "$$\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Input is an array.\n",
    "input_array = np.array([1, 2, 3])\n",
    "exp_array = np.exp(input_array)\n",
    "\n",
    "print(\"Input to exp:\", input_array)\n",
    "print(\"Output of exp:\", exp_array)\n",
    "\n",
    "# Input is a single number\n",
    "input_val = 1\n",
    "exp_val = np.exp(input_val)\n",
    "\n",
    "print(\"Input to exp:\", input_val)\n",
    "print(\"Output of exp:\", exp_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generate an array of evenly spaced values between -10 and 10\n",
    "z_tmp = np.arange(-10, 11)\n",
    "\n",
    "# Use the function implemented above to get the sigmoid values\n",
    "y = sigmoid(z_tmp)\n",
    "\n",
    "# Code for pretty printing the two arrays next to each other\n",
    "np.set_printoptions(precision=3)\n",
    "print(\"Input (z), Output (sigmoid(z))\")\n",
    "print(np.c_[z_tmp, y])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot z vs sigmoid(z)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "ax.plot(z_tmp, y, c=\"b\")\n",
    "\n",
    "ax.set_title(\"Sigmoid function\")\n",
    "ax.set_ylabel('sigmoid(z)')\n",
    "ax.set_xlabel('z')\n",
    "draw_vthresh(ax, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression\n",
    "$$\n",
    "f_{\\mathbf{w},b}(\\mathbf{x})=g(\\mathbf{w} \\cdot \\mathbf{x} + b)=\\frac{1}{1+e^{-(\\mathbf{w} \\cdot \\mathbf{x} + b)}}\\\\\n",
    "=P(y=1|x;\\mathbf{w},b)\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Loss Function\n",
    "$$\n",
    "L(f_{\\mathbf{w}, b}(\\mathbf{x^{(i)}}, y^{(i)}))=\\left\\{\n",
    "\t\t\\begin{aligned}\n",
    "\t\t\t&-\\log(f_{\\mathbf{w},b}(\\mathbf{x})) &y^{(i)} = 1 \\\\\n",
    "\t\t\t&-\\log(1-f_{\\mathbf{w},b}(\\mathbf{x})) &y^{(i)} = 0\n",
    "\t\t\\end{aligned}\n",
    "\t\t\\right.\n",
    "$$\n",
    "损失函数可以简写为\n",
    "$$\n",
    "L(f_{\\mathbf{w}, b}(\\mathbf{x^{(i)}}, y^{(i)}))=(-y^{(i)}\\log(f_{\\mathbf{w},b}(\\mathbf{x^{(i)}}))) - (1 - y^{(i)})\\log(1 - f_{\\mathbf{w},b}(\\mathbf{x^{(i)}}))\n",
    "$$\n",
    "当$y^{(i)}=1$时，上式变为\n",
    "$$\n",
    "    L(f_{\\mathbf{w}, b}(\\mathbf{x^{(i)}}, y^{(i)}))=(-(1)\\log(f_{\\mathbf{w},b}(\\mathbf{x^{(i)}}))) - (1 - 1)\\log(1 - f_{\\mathbf{w},b}(\\mathbf{x^{(i)}}))\n",
    "    = -\\log(f_{\\mathbf{w},b}(\\mathbf{x}))\n",
    "$$\n",
    "当$y^{(i)}=0$时，上式即为\n",
    "$$\n",
    "    L(f_{\\mathbf{w}, b}(\\mathbf{x^{(i)}}, y^{(i)}))=(-(0)^{(i)}\\log(f_{\\mathbf{w},b}(\\mathbf{x^{(i)}}))) - (1 - 0)log(1 - f_{\\mathbf{w},b}(\\mathbf{x^{(i)}})) =-\\log(1-f_{\\mathbf{w},b}(\\mathbf{x}))\n",
    "$$\n",
    "最后，损失函数为\n",
    "$$\n",
    "J(\\mathbf{w}, b) = \\frac{1}{m}\\sum_{i=1}^{m}L(f_{\\mathbf{w}, b}(\\mathbf{x^{(i)}}), y^{(i)}) = \\frac{1}{m}\\sum_{i=1}^{m}[(-y^{(i)}\\log(f_{\\mathbf{w},b}(\\mathbf{x^{(i)}}))) - (1 - y^{(i)})\\log(1 - f_{\\mathbf{w},b}(\\mathbf{x^{(i)}}))]\n",
    "$$\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_cost_logistic(X: np.ndarray, y: np.ndarray, w, b):\n",
    "    m = X.shape[0]\n",
    "    cost = 0.0\n",
    "    for i in range(m):\n",
    "        f = sigmoid(np.dot(X[i], w) + b)\n",
    "        cost += (-y[i]*np.log(f) - (1-y[i])*np.log(1-f))\n",
    "    return cost / m"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train = np.array([[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]])  #(m,n)\n",
    "y_train = np.array([0, 0, 0, 1, 1, 1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w_tmp = np.array([1,1])\n",
    "b_tmp = -3\n",
    "print(compute_cost_logistic(X_train, y_train, w_tmp, b_tmp))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 梯度下降公式\n",
    "$$\n",
    "w_j = w_j - \\alpha[\\frac{1}{m} \\sum_{i=1}^{m} (f_{\\mathbf{w},b}(\\mathbf{x^{(i)}}) - y^{(i)})x_j^{(i)}]\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_gradient_logistic(X: np.ndarray, y: np.ndarray, w, b):\n",
    "    m, n = X.shape\n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0\n",
    "    for i in range(m):\n",
    "        f = sigmoid(np.dot(X[i], w) + b)\n",
    "        error = f - y[i]\n",
    "        for j in range(n):\n",
    "            dj_dw[j] += error * X[i, j]\n",
    "        dj_db += error\n",
    "    return dj_dw / m, dj_db / m"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def gradient_descent(X: np.ndarray, y: np.ndarray, w_in, b_in, alpha, num_iterations):\n",
    "    w = copy.deepcopy(w_in)\n",
    "    b = b_in\n",
    "    J_history = []\n",
    "    for i in range(num_iterations):\n",
    "        dj_dw, dj_db = compute_gradient_logistic(X, y, w, b)\n",
    "        w -= alpha * dj_dw\n",
    "        b -= alpha * dj_db\n",
    "\n",
    "        if i < 100000:\n",
    "            J_history.append(compute_cost_logistic(X, y, w, b))\n",
    "\n",
    "        if i % math.ceil(num_iterations / 10) == 0:\n",
    "            print(f\"Iteration {i:4d}: Cost {J_history[-1]}\")\n",
    "    return w, b, J_history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w_tmp  = np.zeros_like(X_train[0])\n",
    "b_tmp  = 0.\n",
    "alph = 0.1\n",
    "iters = 10000\n",
    "\n",
    "w_out, b_out, J_history = gradient_descent(X_train, y_train, w_tmp, b_tmp, alph, iters)\n",
    "print(f\"\\nupdated parameters: w:{w_out}, b:{b_out}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}